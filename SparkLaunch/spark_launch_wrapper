#!/usr/bin/env python

"""
Usage: prog <num spark nodes> <server callback> <python workflow script> <workflow config file>

Action: Calls script that creates spark cluster and launches spark workflow

Assumptions: The environment should be properly set by the driver.
"""

import sys
import os


# use current environment and launch with number of machines (16 cores) + 1 for master
command = "qsub -jc spark -pe spark " + str(int(sys.argv[1])+1) + " -q hadoop2 -j y -V -o ~/.spark/ugelogs -m b spark_launch "

# add python script location and its configuration file
command += " ".join(sys.argv[2:])

#command += "sparklaunch.sh"

os.system(command)

#print command
#print command.split(' ')
#results = subprocess.check_output(command.split(' '))
#print results

